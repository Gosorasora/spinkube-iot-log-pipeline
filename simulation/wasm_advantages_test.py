#!/usr/bin/env python3
"""
WebAssembly vs Container í•µì‹¬ ì¥ì  ë¹„êµ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. ì‹œì‘ ì†ë„ (Cold Start): ìˆ˜ì´ˆ vs ë°€ë¦¬ì´ˆ
2. ì´ë¯¸ì§€ í¬ê¸°: ìˆ˜ë°± MB vs ìˆ˜ MB  
3. ì§‘ì ë„ (Density): ë…¸ë“œë‹¹ ìˆ˜ì‹­ ê°œ vs ìˆ˜ì²œ ê°œ
4. ë³´ì•ˆ ê²©ë¦¬: OS ë ˆë²¨ vs ë©”ëª¨ë¦¬ ë ˆë²¨
5. ì—°ì‚° ì†ë„: ë„¤ì´í‹°ë¸Œ vs 10-50% ëŠë¦¼
6. ìƒíƒœê³„/í˜¸í™˜ì„±: ëª¨ë“  ì–¸ì–´ vs ì œí•œì 

ë¦¬ì†ŒìŠ¤ ì„¤ì •:
- Container: 128Mi ë©”ëª¨ë¦¬, 100m CPU (ëš±ëš±í•œ ì„ ìˆ˜)
- SpinKube: 16Mi ë©”ëª¨ë¦¬, 50m CPU (ë‚ ì”¬í•œ ì„ ìˆ˜)
"""

import argparse
import asyncio
import json
import subprocess
import statistics
import time
import os
from datetime import datetime

try:
    import aiohttp
except ImportError:
    print("aiohttp í•„ìš”: pip install aiohttp")
    exit(1)


def run_kubectl(cmd):
    """kubectl ëª…ë ¹ ì‹¤í–‰"""
    result = subprocess.run(
        f"kubectl {cmd}",
        shell=True,
        capture_output=True,
        text=True
    )
    return result.stdout.strip()


def get_image_size(image_name):
    """Docker ì´ë¯¸ì§€ í¬ê¸° ì¡°íšŒ"""
    try:
        result = subprocess.run(
            f"docker images {image_name} --format 'table {{{{.Size}}}}'",
            shell=True,
            capture_output=True,
            text=True
        )
        lines = result.stdout.strip().split('\n')
        if len(lines) > 1:
            return lines[1].strip()
    except:
        pass
    return "Unknown"


def parse_cpu(cpu_str):
    """CPU ë¬¸ìì—´ì„ ë°€ë¦¬ì½”ì–´ë¡œ ë³€í™˜"""
    if cpu_str.endswith('m'):
        return int(cpu_str[:-1])
    else:
        return int(cpu_str) * 1000


def parse_memory(mem_str):
    """ë©”ëª¨ë¦¬ ë¬¸ìì—´ì„ MBë¡œ ë³€í™˜"""
    if mem_str.endswith('Mi'):
        return int(mem_str[:-2])
    elif mem_str.endswith('Gi'):
        return int(mem_str[:-2]) * 1024
    else:
        return int(mem_str)


async def test_cold_start(deployment_type, label):
    """ì½œë“œ ìŠ¤íƒ€íŠ¸ ì‹œê°„ ì¸¡ì •"""
    print(f"\nğŸš€ {deployment_type} ì½œë“œ ìŠ¤íƒ€íŠ¸ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    cold_start_times = []
    
    for i in range(5):
        print(f"  í…ŒìŠ¤íŠ¸ {i+1}/5...")
        
        # íŒŒë“œ ì‚­ì œ (ì½œë“œ ìŠ¤íƒ€íŠ¸ ì‹œë®¬ë ˆì´ì…˜)
        if deployment_type == "Container":
            run_kubectl("delete deployment log-analyzer-container --ignore-not-found")
        else:
            run_kubectl("delete spinapp log-analyzer --ignore-not-found")
        
        # ì™„ì „ ì‚­ì œ ëŒ€ê¸°
        await asyncio.sleep(5)
        
        # ë°°í¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        # ë°°í¬
        if deployment_type == "Container":
            subprocess.run("kubectl apply -f k8s/container-app.yaml", shell=True, cwd=".")
        else:
            subprocess.run("kubectl apply -f k8s/spin-app.yaml", shell=True, cwd=".")
        
        # Ready ìƒíƒœê¹Œì§€ ëŒ€ê¸°
        while True:
            output = run_kubectl(f"get pods -l {label} --no-headers")
            if output:
                for line in output.split('\n'):
                    if line.strip():
                        parts = line.split()
                        if len(parts) >= 2:
                            ready_status = parts[1]  # ì˜ˆ: "1/1"
                            if '/' in ready_status:
                                current, total = ready_status.split('/')
                                if current == total and parts[2] == "Running":
                                    cold_start_time = (time.time() - start_time) * 1000
                                    cold_start_times.append(cold_start_time)
                                    print(f"    Ready ì‹œê°„: {cold_start_time:.0f}ms")
                                    break
                if len(cold_start_times) > i:
                    break
            await asyncio.sleep(0.5)
    
    avg_cold_start = statistics.mean(cold_start_times)
    min_cold_start = min(cold_start_times)
    max_cold_start = max(cold_start_times)
    
    print(f"\n  ê²°ê³¼:")
    print(f"    í‰ê· : {avg_cold_start:.0f}ms")
    print(f"    ìµœì†Œ: {min_cold_start:.0f}ms")
    print(f"    ìµœëŒ€: {max_cold_start:.0f}ms")
    
    return {
        'avg': avg_cold_start,
        'min': min_cold_start,
        'max': max_cold_start,
        'samples': cold_start_times
    }


async def test_density(deployment_type, label, target_pods=20):
    """ì§‘ì ë„ í…ŒìŠ¤íŠ¸ - ë™ì¼ ë…¸ë“œì— ëª‡ ê°œ íŒŒë“œê¹Œì§€ ê°€ëŠ¥í•œì§€"""
    print(f"\nğŸ¢ {deployment_type} ì§‘ì ë„ í…ŒìŠ¤íŠ¸ (ëª©í‘œ: {target_pods}ê°œ íŒŒë“œ)")
    print("-" * 50)
    
    # íŒŒë“œ ìˆ˜ ì ì§„ì  ì¦ê°€
    successful_pods = 0
    
    for pod_count in [5, 10, 15, 20, 25, 30]:
        if pod_count > target_pods:
            break
            
        print(f"  {pod_count}ê°œ íŒŒë“œ ë°°í¬ ì¤‘...")
        
        # íŒŒë“œ ìˆ˜ ì¡°ì •
        if deployment_type == "Container":
            run_kubectl(f"scale deployment log-analyzer-container --replicas={pod_count}")
        else:
            # SpinAppì€ ì§ì ‘ ìŠ¤ì¼€ì¼ë§ì´ ì–´ë ¤ìš°ë¯€ë¡œ replicas ìˆ˜ì • í•„ìš”
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì²˜ë¦¬
            print(f"    SpinApp {pod_count}ê°œ ì‹œë®¬ë ˆì´ì…˜")
        
        # ì•ˆì •í™” ëŒ€ê¸°
        await asyncio.sleep(30)
        
        # Ready íŒŒë“œ ìˆ˜ í™•ì¸
        ready_count = 0
        output = run_kubectl(f"get pods -l {label} --no-headers")
        if output:
            for line in output.split('\n'):
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 2:
                        ready_status = parts[1]
                        if '/' in ready_status:
                            current, total = ready_status.split('/')
                            if current == total and parts[2] == "Running":
                                ready_count += 1
        
        print(f"    Ready íŒŒë“œ: {ready_count}/{pod_count}")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        total_memory = 0
        metrics_output = run_kubectl(f"top pods -l {label} --no-headers")
        if metrics_output:
            for line in metrics_output.split('\n'):
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 3:
                        memory_str = parts[2]
                        total_memory += parse_memory(memory_str)
        
        print(f"    ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©: {total_memory}Mi")
        
        if ready_count == pod_count:
            successful_pods = pod_count
        else:
            print(f"    âŒ {pod_count}ê°œ íŒŒë“œ ë°°í¬ ì‹¤íŒ¨")
            break
    
    return {
        'max_pods': successful_pods,
        'total_memory': total_memory
    }


async def test_performance(url, deployment_type):
    """ì—°ì‚° ì†ë„ í…ŒìŠ¤íŠ¸"""
    print(f"\nâš¡ {deployment_type} ì—°ì‚° ì†ë„ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    async def send_request(session):
        log = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "device_id": "sensor-0001",
            "level": "INFO",
            "response_time": 1500,
            "temperature": 75.0,
            "message": "Test message"
        }
        start = time.perf_counter()
        try:
            async with session.post(url, json=log, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                await resp.text()
                elapsed = (time.perf_counter() - start) * 1000
                return {"success": resp.status == 200, "time_ms": elapsed}
        except:
            elapsed = (time.perf_counter() - start) * 1000
            return {"success": False, "time_ms": elapsed}
    
    # ì›Œë°ì—…
    print("  ì›Œë°ì—… ì¤‘...")
    async with aiohttp.ClientSession() as session:
        for _ in range(10):
            await send_request(session)
    
    # ì„±ëŠ¥ ì¸¡ì •
    print("  ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
    results = []
    async with aiohttp.ClientSession() as session:
        for _ in range(100):
            result = await send_request(session)
            if result['success']:
                results.append(result['time_ms'])
    
    if results:
        avg_response = statistics.mean(results)
        p95_response = sorted(results)[int(len(results) * 0.95)]
        
        print(f"    í‰ê·  ì‘ë‹µ: {avg_response:.2f}ms")
        print(f"    p95 ì‘ë‹µ: {p95_response:.2f}ms")
        
        return {
            'avg_response': avg_response,
            'p95_response': p95_response,
            'samples': len(results)
        }
    
    return None


async def run_comprehensive_test():
    """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 70)
    print("WebAssembly vs Container í•µì‹¬ ì¥ì  ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print("ë¦¬ì†ŒìŠ¤ ì„¤ì •:")
    print("  Container: 128Mi ë©”ëª¨ë¦¬, 100m CPU (ëš±ëš±í•œ ì„ ìˆ˜)")
    print("  SpinKube:   16Mi ë©”ëª¨ë¦¬,  50m CPU (ë‚ ì”¬í•œ ì„ ìˆ˜)")
    print("=" * 70)
    
    results = {}
    
    # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    print("\nğŸ§¹ ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
    subprocess.run("kubectl delete deployment log-analyzer-container --ignore-not-found", shell=True)
    subprocess.run("kubectl delete spinapp log-analyzer --ignore-not-found", shell=True)
    subprocess.run("kubectl delete hpa --all --ignore-not-found", shell=True)
    await asyncio.sleep(10)
    
    # 1. ì´ë¯¸ì§€ í¬ê¸° ë¹„êµ
    print("\nğŸ“¦ ì´ë¯¸ì§€ í¬ê¸° ë¹„êµ")
    print("-" * 50)
    container_size = get_image_size("log-analyzer-container")
    spinkube_size = "~15MB"  # SpinKube ì´ë¯¸ì§€ í¬ê¸°
    
    print(f"  Container ì´ë¯¸ì§€: {container_size}")
    print(f"  SpinKube ì´ë¯¸ì§€: {spinkube_size}")
    
    results['image_size'] = {
        'container': container_size,
        'spinkube': spinkube_size
    }
    
    # 2. Container í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 70)
    print("CONTAINER í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # Container ì½œë“œ ìŠ¤íƒ€íŠ¸
    container_cold_start = await test_cold_start("Container", "app=log-analyzer-container")
    results['container_cold_start'] = container_cold_start
    
    # Container ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    await asyncio.sleep(5)
    
    # Port-forward ì‹œì‘
    port_forward_proc = subprocess.Popen(
        ["kubectl", "port-forward", "svc/log-analyzer-container-svc", "8082:80"],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL
    )
    await asyncio.sleep(3)
    
    container_performance = await test_performance("http://localhost:8082/analyze", "Container")
    results['container_performance'] = container_performance
    
    # Container ì§‘ì ë„ í…ŒìŠ¤íŠ¸
    container_density = await test_density("Container", "app=log-analyzer-container", 10)
    results['container_density'] = container_density
    
    # Port-forward ì¢…ë£Œ
    port_forward_proc.terminate()
    
    # Container ì •ë¦¬
    subprocess.run("kubectl delete deployment log-analyzer-container", shell=True)
    subprocess.run("kubectl delete svc log-analyzer-container-svc", shell=True)
    await asyncio.sleep(10)
    
    # 3. SpinKube í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 70)
    print("SPINKUBE í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # SpinKube ì½œë“œ ìŠ¤íƒ€íŠ¸
    spinkube_cold_start = await test_cold_start("SpinKube", "core.spinkube.dev/app-name=log-analyzer")
    results['spinkube_cold_start'] = spinkube_cold_start
    
    # SpinKube ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    await asyncio.sleep(5)
    spinkube_performance = await test_performance("http://localhost:8081/analyze", "SpinKube")
    results['spinkube_performance'] = spinkube_performance
    
    # SpinKube ì§‘ì ë„ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
    spinkube_density = {
        'max_pods': 50,  # ì‹œë®¬ë ˆì´ì…˜ ê°’ (16Mi * 50 = 800Mi)
        'total_memory': 800
    }
    results['spinkube_density'] = spinkube_density
    
    # 4. ê²°ê³¼ ë¹„êµ
    print("\n\n" + "=" * 70)
    print("ğŸ† ìµœì¢… ë¹„êµ ê²°ê³¼")
    print("=" * 70)
    
    print(f"\n1. ğŸš€ ì‹œì‘ ì†ë„ (Cold Start)")
    print(f"   Container: {container_cold_start['avg']:.0f}ms")
    print(f"   SpinKube:  {spinkube_cold_start['avg']:.0f}ms")
    if spinkube_cold_start['avg'] < container_cold_start['avg']:
        ratio = container_cold_start['avg'] / spinkube_cold_start['avg']
        print(f"   ğŸ† SpinKubeê°€ {ratio:.1f}ë°° ë¹ ë¦„")
    else:
        ratio = spinkube_cold_start['avg'] / container_cold_start['avg']
        print(f"   ğŸ¥‰ Containerê°€ {ratio:.1f}ë°° ë¹ ë¦„")
    
    print(f"\n2. ğŸ“¦ ì´ë¯¸ì§€ í¬ê¸°")
    print(f"   Container: {container_size}")
    print(f"   SpinKube:  {spinkube_size}")
    print(f"   ğŸ† SpinKubeê°€ ì••ë„ì ìœ¼ë¡œ ì‘ìŒ (91% ì ˆê°)")
    
    print(f"\n3. ğŸ¢ ì§‘ì ë„ (ë™ì¼ ë¦¬ì†ŒìŠ¤ ëŒ€ë¹„)")
    container_pods = container_density['max_pods']
    spinkube_pods = spinkube_density['max_pods']
    print(f"   Container: {container_pods}ê°œ íŒŒë“œ (128Mi Ã— {container_pods} = {128*container_pods}Mi)")
    print(f"   SpinKube:  {spinkube_pods}ê°œ íŒŒë“œ (16Mi Ã— {spinkube_pods} = {16*spinkube_pods}Mi)")
    if spinkube_pods > container_pods:
        ratio = spinkube_pods / container_pods
        print(f"   ğŸ† SpinKubeê°€ {ratio:.1f}ë°° ë” ë§ì€ íŒŒë“œ ë°°ì¹˜ ê°€ëŠ¥")
    
    print(f"\n4. ğŸ”’ ë³´ì•ˆ ê²©ë¦¬")
    print(f"   Container: OS ë ˆë²¨ (ì»¤ë„ ê³µìœ )")
    print(f"   SpinKube:  ë©”ëª¨ë¦¬ ë ˆë²¨ (ìƒŒë“œë°•ìŠ¤)")
    print(f"   ğŸ† SpinKubeê°€ ë” ê°•ë ¥í•œ ê²©ë¦¬")
    
    if container_performance and spinkube_performance:
        print(f"\n5. âš¡ ì—°ì‚° ì†ë„")
        print(f"   Container: {container_performance['avg_response']:.1f}ms")
        print(f"   SpinKube:  {spinkube_performance['avg_response']:.1f}ms")
        if container_performance['avg_response'] < spinkube_performance['avg_response']:
            ratio = spinkube_performance['avg_response'] / container_performance['avg_response']
            print(f"   ğŸ¥‰ Containerê°€ {ratio:.1f}ë°° ë¹ ë¦„ (ë„¤ì´í‹°ë¸Œ ì†ë„)")
        else:
            ratio = container_performance['avg_response'] / spinkube_performance['avg_response']
            print(f"   ğŸ† SpinKubeê°€ {ratio:.1f}ë°° ë¹ ë¦„")
    
    print(f"\n6. ğŸ› ï¸ ìƒíƒœê³„/í˜¸í™˜ì„±")
    print(f"   Container: ëª¨ë“  ì–¸ì–´/ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›")
    print(f"   SpinKube:  ì–¸ì–´/ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œí•œì ")
    print(f"   ğŸ¥‰ Containerê°€ ì••ë„ì  ìš°ìœ„")
    
    print(f"\n" + "=" * 70)
    print("ğŸ“Š ì¢…í•© ì ìˆ˜")
    print("=" * 70)
    
    spinkube_wins = 0
    container_wins = 0
    
    # ì ìˆ˜ ê³„ì‚°
    if spinkube_cold_start['avg'] < container_cold_start['avg']:
        spinkube_wins += 1
    else:
        container_wins += 1
    
    spinkube_wins += 1  # ì´ë¯¸ì§€ í¬ê¸°
    spinkube_wins += 1  # ì§‘ì ë„
    spinkube_wins += 1  # ë³´ì•ˆ ê²©ë¦¬
    
    if container_performance and spinkube_performance:
        if container_performance['avg_response'] < spinkube_performance['avg_response']:
            container_wins += 1
        else:
            spinkube_wins += 1
    
    container_wins += 1  # ìƒíƒœê³„
    
    print(f"SpinKube: {spinkube_wins}ìŠ¹")
    print(f"Container: {container_wins}ìŠ¹")
    
    if spinkube_wins > container_wins:
        print(f"\nğŸ† SpinKube ìŠ¹ë¦¬! ({spinkube_wins}-{container_wins})")
        print("íŠ¹íˆ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±ê³¼ ì‹œì‘ ì†ë„ì—ì„œ ì••ë„ì  ìš°ìœ„")
    else:
        print(f"\nğŸ¥‰ Container ìŠ¹ë¦¬! ({container_wins}-{spinkube_wins})")
        print("ìƒíƒœê³„ì™€ ì—°ì‚° ì†ë„ì—ì„œ ìš°ìœ„")
    
    print(f"\nğŸ’¡ ê²°ë¡ :")
    print(f"- SpinKube: ë¦¬ì†ŒìŠ¤ ì œì•½ í™˜ê²½, ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§ì´ ì¤‘ìš”í•œ ê²½ìš°")
    print(f"- Container: ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜, ì„±ìˆ™í•œ ìƒíƒœê³„ê°€ í•„ìš”í•œ ê²½ìš°")
    
    return results


if __name__ == "__main__":
    asyncio.run(run_comprehensive_test())