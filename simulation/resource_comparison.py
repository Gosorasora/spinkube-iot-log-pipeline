#!/usr/bin/env python3
"""
Container vs SpinKube ë¦¬ì†ŒìŠ¤ ë¹„êµ í…ŒìŠ¤íŠ¸

ë™ì¼í•œ ë¶€í•˜ì—ì„œ Containerì™€ SpinKubeì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ê³¼ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

ì¸¡ì • í•­ëª©:
  1. íŒŒë“œ ìˆ˜
  2. CPU ì‚¬ìš©ëŸ‰
  3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
  4. ì²˜ë¦¬ëŸ‰
  5. ì‘ë‹µ ì‹œê°„
  6. ìŠ¤ì¼€ì¼ ì•„ì›ƒ ì‹œê°„

ì‚¬ìš©ë²•:
  python resource_comparison.py --container-url http://localhost:8082/analyze --spinkube-url http://localhost:8081/analyze --requests 10000 --concurrency 500
"""

import argparse
import asyncio
import json
import subprocess
import statistics
import time
from datetime import datetime

try:
    import aiohttp
except ImportError:
    print("aiohttp í•„ìš”: pip install aiohttp")
    exit(1)


def run_kubectl(cmd):
    """kubectl ëª…ë ¹ ì‹¤í–‰"""
    result = subprocess.run(
        f"kubectl {cmd}",
        shell=True,
        capture_output=True,
        text=True
    )
    return result.stdout.strip()


def get_pod_metrics(label):
    """íŒŒë“œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    output = run_kubectl(f"top pods -l {label} --no-headers")
    if not output:
        return []
    
    metrics = []
    for line in output.split('\n'):
        if line.strip():
            parts = line.split()
            if len(parts) >= 3:
                metrics.append({
                    'name': parts[0],
                    'cpu': parts[1],
                    'memory': parts[2]
                })
    return metrics


def get_pod_count(label):
    """íŒŒë“œ ìˆ˜ ì¡°íšŒ"""
    output = run_kubectl(f"get pods -l {label} --no-headers")
    if not output:
        return 0
    return len([line for line in output.split('\n') if line.strip()])


def parse_cpu(cpu_str):
    """CPU ë¬¸ìì—´ì„ ë°€ë¦¬ì½”ì–´ë¡œ ë³€í™˜ (ì˜ˆ: 100m -> 100, 1 -> 1000)"""
    if cpu_str.endswith('m'):
        return int(cpu_str[:-1])
    else:
        return int(cpu_str) * 1000


def parse_memory(mem_str):
    """ë©”ëª¨ë¦¬ ë¬¸ìì—´ì„ MBë¡œ ë³€í™˜ (ì˜ˆ: 100Mi -> 100, 1Gi -> 1024)"""
    if mem_str.endswith('Mi'):
        return int(mem_str[:-2])
    elif mem_str.endswith('Gi'):
        return int(mem_str[:-2]) * 1024
    else:
        return int(mem_str)


async def send_request(session, url):
    """ë‹¨ì¼ ìš”ì²­ ì „ì†¡"""
    log = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "device_id": "sensor-0001",
        "level": "INFO",
        "response_time": 1500,
        "temperature": 75.0,
        "message": "Test message"
    }
    start = time.perf_counter()
    try:
        async with session.post(url, json=log, timeout=aiohttp.ClientTimeout(total=10)) as resp:
            await resp.text()
            elapsed = (time.perf_counter() - start) * 1000
            return {"success": resp.status == 200, "time_ms": elapsed}
    except Exception as e:
        elapsed = (time.perf_counter() - start) * 1000
        return {"success": False, "time_ms": elapsed}


async def run_load_test(url, total_requests, concurrency, label, name):
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
    print(f"\n{'=' * 70}")
    print(f"{name} í…ŒìŠ¤íŠ¸")
    print(f"{'=' * 70}")
    print(f"ëŒ€ìƒ: {url}")
    print(f"ìš”ì²­ ìˆ˜: {total_requests}, ë™ì‹œì„±: {concurrency}")
    print("-" * 70)
    
    # ì´ˆê¸° ìƒíƒœ
    initial_pods = get_pod_count(label)
    print(f"\nì´ˆê¸° íŒŒë“œ ìˆ˜: {initial_pods}")
    
    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬
    resource_samples = []
    monitoring = True
    
    async def monitor_resources():
        while monitoring:
            metrics = get_pod_metrics(label)
            pod_count = get_pod_count(label)
            if metrics:
                total_cpu = sum(parse_cpu(m['cpu']) for m in metrics)
                total_memory = sum(parse_memory(m['memory']) for m in metrics)
                resource_samples.append({
                    'time': time.time(),
                    'pod_count': pod_count,
                    'total_cpu_m': total_cpu,
                    'total_memory_mb': total_memory,
                    'pods': metrics
                })
            await asyncio.sleep(2)
    
    monitor_task = asyncio.create_task(monitor_resources())
    
    # ë¶€í•˜ í…ŒìŠ¤íŠ¸
    print(f"\në¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    start_time = time.time()
    results = []
    
    async with aiohttp.ClientSession() as session:
        # ìš”ì²­ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì „ì†¡
        batch_size = concurrency
        for i in range(0, total_requests, batch_size):
            batch_count = min(batch_size, total_requests - i)
            tasks = [send_request(session, url) for _ in range(batch_count)]
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)
            
            if (i + batch_count) % 1000 == 0:
                elapsed = time.time() - start_time
                print(f"  ì§„í–‰: {i + batch_count}/{total_requests} ìš”ì²­ ({elapsed:.1f}ì´ˆ)")
    
    total_time = time.time() - start_time
    
    # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
    monitoring = False
    await monitor_task
    
    # ìµœì¢… ìƒíƒœ
    await asyncio.sleep(5)  # ë§ˆì§€ë§‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    final_pods = get_pod_count(label)
    final_metrics = get_pod_metrics(label)
    
    # ê²°ê³¼ ë¶„ì„
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    if successful:
        times = [r["time_ms"] for r in successful]
        times_sorted = sorted(times)
        p95_idx = int(len(times_sorted) * 0.95)
        p99_idx = int(len(times_sorted) * 0.99)
        
        print(f"\n{'=' * 70}")
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print(f"{'=' * 70}")
        
        print(f"\nğŸ“Š ìš”ì²­ í†µê³„:")
        print(f"  ì´ ìš”ì²­: {total_requests}")
        print(f"  ì„±ê³µ: {len(successful)} ({len(successful)/total_requests*100:.1f}%)")
        print(f"  ì‹¤íŒ¨: {len(failed)} ({len(failed)/total_requests*100:.1f}%)")
        print(f"  ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"  ì²˜ë¦¬ëŸ‰: {len(successful)/total_time:.1f} req/s")
        
        print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„:")
        print(f"  í‰ê· : {statistics.mean(times):.2f}ms")
        print(f"  ì¤‘ì•™ê°’: {statistics.median(times):.2f}ms")
        print(f"  p95: {times_sorted[p95_idx]:.2f}ms")
        print(f"  p99: {times_sorted[p99_idx]:.2f}ms")
        print(f"  ìµœëŒ€: {max(times):.2f}ms")
        
        print(f"\nğŸ”§ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©:")
        print(f"  ì´ˆê¸° íŒŒë“œ: {initial_pods}")
        print(f"  ìµœì¢… íŒŒë“œ: {final_pods}")
        print(f"  ìµœëŒ€ íŒŒë“œ: {max(s['pod_count'] for s in resource_samples) if resource_samples else final_pods}")
        
        if resource_samples:
            avg_cpu = statistics.mean(s['total_cpu_m'] for s in resource_samples)
            max_cpu = max(s['total_cpu_m'] for s in resource_samples)
            avg_memory = statistics.mean(s['total_memory_mb'] for s in resource_samples)
            max_memory = max(s['total_memory_mb'] for s in resource_samples)
            
            print(f"  í‰ê·  CPU: {avg_cpu:.0f}m")
            print(f"  ìµœëŒ€ CPU: {max_cpu:.0f}m")
            print(f"  í‰ê·  ë©”ëª¨ë¦¬: {avg_memory:.0f}Mi")
            print(f"  ìµœëŒ€ ë©”ëª¨ë¦¬: {max_memory:.0f}Mi")
        
        if final_metrics:
            print(f"\nğŸ“¦ ìµœì¢… íŒŒë“œ ìƒíƒœ:")
            for m in final_metrics:
                print(f"  {m['name']}: CPU {m['cpu']}, Memory {m['memory']}")
        
        print(f"\n{'=' * 70}")
        
        return {
            'name': name,
            'total_requests': total_requests,
            'successful': len(successful),
            'failed': len(failed),
            'success_rate': len(successful)/total_requests*100,
            'total_time': total_time,
            'throughput': len(successful)/total_time,
            'avg_response_ms': statistics.mean(times),
            'p95_response_ms': times_sorted[p95_idx],
            'p99_response_ms': times_sorted[p99_idx],
            'initial_pods': initial_pods,
            'final_pods': final_pods,
            'max_pods': max(s['pod_count'] for s in resource_samples) if resource_samples else final_pods,
            'avg_cpu_m': statistics.mean(s['total_cpu_m'] for s in resource_samples) if resource_samples else 0,
            'max_cpu_m': max(s['total_cpu_m'] for s in resource_samples) if resource_samples else 0,
            'avg_memory_mb': statistics.mean(s['total_memory_mb'] for s in resource_samples) if resource_samples else 0,
            'max_memory_mb': max(s['total_memory_mb'] for s in resource_samples) if resource_samples else 0,
        }


async def compare(container_url, spinkube_url, total_requests, concurrency):
    """Container vs SpinKube ë¹„êµ"""
    print("=" * 70)
    print("Container vs SpinKube ë¦¬ì†ŒìŠ¤ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # Container í…ŒìŠ¤íŠ¸
    container_result = await run_load_test(
        container_url,
        total_requests,
        concurrency,
        "app=log-analyzer-container",
        "CONTAINER"
    )
    
    if not container_result:
        print("âŒ Container í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return
    
    print("\n\nëŒ€ê¸° ì¤‘... (60ì´ˆ)")
    await asyncio.sleep(60)
    
    # SpinKube í…ŒìŠ¤íŠ¸
    spinkube_result = await run_load_test(
        spinkube_url,
        total_requests,
        concurrency,
        "core.spinkube.dev/app-name=log-analyzer",
        "SPINKUBE"
    )
    
    if not spinkube_result:
        print("âŒ SpinKube í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return
    
    # ë¹„êµ ê²°ê³¼
    print("\n\n" + "=" * 70)
    print("ë¹„êµ ê²°ê³¼")
    print("=" * 70)
    
    print(f"\n{'í•­ëª©':<20} {'Container':>20} {'SpinKube':>20} {'ì°¨ì´':>15}")
    print("-" * 70)
    
    def compare_metric(name, container_val, spinkube_val, unit="", reverse=False):
        if spinkube_val > 0:
            if reverse:
                ratio = container_val / spinkube_val
                better = "Container" if ratio < 1 else "SpinKube"
            else:
                ratio = spinkube_val / container_val
                better = "SpinKube" if ratio > 1 else "Container"
            diff = f"{ratio:.2f}x ({better})"
        else:
            diff = "N/A"
        print(f"{name:<20} {container_val:>19}{unit} {spinkube_val:>19}{unit} {diff:>15}")
    
    compare_metric("ì²˜ë¦¬ëŸ‰", f"{container_result['throughput']:.1f}", f"{spinkube_result['throughput']:.1f}", " req/s")
    compare_metric("í‰ê·  ì‘ë‹µì‹œê°„", f"{container_result['avg_response_ms']:.1f}", f"{spinkube_result['avg_response_ms']:.1f}", "ms", reverse=True)
    compare_metric("p95 ì‘ë‹µì‹œê°„", f"{container_result['p95_response_ms']:.1f}", f"{spinkube_result['p95_response_ms']:.1f}", "ms", reverse=True)
    compare_metric("ìµœëŒ€ íŒŒë“œ ìˆ˜", container_result['max_pods'], spinkube_result['max_pods'], "", reverse=True)
    compare_metric("í‰ê·  CPU", f"{container_result['avg_cpu_m']:.0f}", f"{spinkube_result['avg_cpu_m']:.0f}", "m", reverse=True)
    compare_metric("ìµœëŒ€ CPU", f"{container_result['max_cpu_m']:.0f}", f"{spinkube_result['max_cpu_m']:.0f}", "m", reverse=True)
    compare_metric("í‰ê·  ë©”ëª¨ë¦¬", f"{container_result['avg_memory_mb']:.0f}", f"{spinkube_result['avg_memory_mb']:.0f}", "Mi", reverse=True)
    compare_metric("ìµœëŒ€ ë©”ëª¨ë¦¬", f"{container_result['max_memory_mb']:.0f}", f"{spinkube_result['max_memory_mb']:.0f}", "Mi", reverse=True)
    
    print("\n" + "=" * 70)


def main():
    parser = argparse.ArgumentParser(description="Container vs SpinKube ë¦¬ì†ŒìŠ¤ ë¹„êµ")
    parser.add_argument("--container-url", required=True, help="Container ì„œë¹„ìŠ¤ URL")
    parser.add_argument("--spinkube-url", required=True, help="SpinKube ì„œë¹„ìŠ¤ URL")
    parser.add_argument("--requests", type=int, default=10000, help="ì´ ìš”ì²­ ìˆ˜")
    parser.add_argument("--concurrency", type=int, default=500, help="ë™ì‹œ ìš”ì²­ ìˆ˜")
    
    args = parser.parse_args()
    asyncio.run(compare(args.container_url, args.spinkube_url, args.requests, args.concurrency))


if __name__ == "__main__":
    main()
